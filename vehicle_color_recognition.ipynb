{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VehicleColorRecognitionModel(\n",
       "  (top_conv1): Sequential(\n",
       "    (0): Conv2d(3, 48, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (top_top_conv2): Sequential(\n",
       "    (0): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (top_bot_conv2): Sequential(\n",
       "    (0): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (top_conv3): Sequential(\n",
       "    (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (top_top_conv4): Sequential(\n",
       "    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (top_bot_conv4): Sequential(\n",
       "    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (top_top_conv5): Sequential(\n",
       "    (0): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (top_bot_conv5): Sequential(\n",
       "    (0): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottom_conv1): Sequential(\n",
       "    (0): Conv2d(3, 48, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottom_top_conv2): Sequential(\n",
       "    (0): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottom_bot_conv2): Sequential(\n",
       "    (0): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottom_conv3): Sequential(\n",
       "    (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (bottom_top_conv4): Sequential(\n",
       "    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (bottom_bot_conv4): Sequential(\n",
       "    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (bottom_top_conv5): Sequential(\n",
       "    (0): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottom_bot_conv5): Sequential(\n",
       "    (0): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.7, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.6, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import  models, transforms,datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os,cv2\n",
    "from torch.utils.data import Dataset\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from PIL import Image\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "num_classes = 4\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "img_size = 224\n",
    "# 定义一个类，需要创建模型的时候，就实例化一个对象\n",
    "\n",
    "class VehicleColorRecognitionModel(nn.Module):\n",
    "    def __init__(self,Load_VIS_URL=None):\n",
    "        super(VehicleColorRecognitionModel,self).__init__()\n",
    "        \n",
    "        # ===============================  top ================================\n",
    "        # first top convolution layer   \n",
    "        self.top_conv1 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(3, 48, kernel_size=(11,11), stride=(4,4)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "       \n",
    "        \n",
    "        # first top convolution layer    after split\n",
    "        self.top_top_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.top_bot_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        #  need a concat\n",
    "        \n",
    "        # after concat  \n",
    "        self.top_conv3 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(128, 192, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # fourth top convolution layer\n",
    "        # split feature map by half\n",
    "        self.top_top_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.top_bot_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # fifth top convolution layer\n",
    "        self.top_top_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.top_bot_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "#        # ===============================  bottom ================================\n",
    "    \n",
    "           \n",
    "#         # first bottom convolution layer   \n",
    "        self.bottom_conv1 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(3, 48, kernel_size=(11,11), stride=(4,4)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "       \n",
    "        \n",
    "        # first top convolution layer    after split\n",
    "        self.bottom_top_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.bottom_bot_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        #  need a concat\n",
    "        \n",
    "        # after concat  \n",
    "        self.bottom_conv3 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(128, 192, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # fourth top convolution layer\n",
    "        # split feature map by half\n",
    "        self.bottom_top_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.bottom_bot_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # fifth top convolution layer\n",
    "        self.bottom_top_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.bottom_bot_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Fully-connected layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(5*5*64*4, 4096), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )                \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        x_top = self.top_conv1(x)\n",
    "        #print(x_top.shape)\n",
    "                \n",
    "        x_top_conv = torch.split(x_top, 24, 1)\n",
    "        \n",
    "        x_top_top_conv2 = self.top_top_conv2(x_top_conv[0])\n",
    "        x_top_bot_conv2 = self.top_bot_conv2(x_top_conv[1])\n",
    "        \n",
    "        x_top_cat1 = torch.cat([x_top_top_conv2,x_top_bot_conv2],1)\n",
    "        \n",
    "        x_top_conv3 = self.top_conv3(x_top_cat1)\n",
    "        \n",
    "        x_top_conv3 = torch.split(x_top_conv3, 96, 1)\n",
    "        \n",
    "        x_top_top_conv4 = self.top_top_conv4(x_top_conv3[0])\n",
    "        x_top_bot_conv4 = self.top_bot_conv4(x_top_conv3[1])\n",
    "        \n",
    "        x_top_top_conv5 = self.top_top_conv5(x_top_top_conv4)\n",
    "        x_top_bot_conv5 = self.top_bot_conv5(x_top_bot_conv4)\n",
    "        \n",
    "        x_bottom = self.bottom_conv1(x)\n",
    "        \n",
    "        x_bottom_conv = torch.split(x_bottom, 24, 1)\n",
    "        \n",
    "        x_bottom_top_conv2 = self.bottom_top_conv2(x_bottom_conv[0])\n",
    "        x_bottom_bot_conv2 = self.bottom_bot_conv2(x_bottom_conv[1])\n",
    "        \n",
    "        x_bottom_cat1 = torch.cat([x_bottom_top_conv2,x_bottom_bot_conv2],1)\n",
    "        \n",
    "        x_bottom_conv3 = self.bottom_conv3(x_bottom_cat1)\n",
    "        \n",
    "        x_bottom_conv3 = torch.split(x_bottom_conv3, 96, 1)\n",
    "        \n",
    "        x_bottom_top_conv4 = self.bottom_top_conv4(x_bottom_conv3[0])\n",
    "        x_bottom_bot_conv4 = self.bottom_bot_conv4(x_bottom_conv3[1])\n",
    "        \n",
    "        x_bottom_top_conv5 = self.bottom_top_conv5(x_bottom_top_conv4)\n",
    "        x_bottom_bot_conv5 = self.bottom_bot_conv5(x_bottom_bot_conv4)\n",
    "        \n",
    "        x_cat = torch.cat([x_top_top_conv5,x_top_bot_conv5,x_bottom_top_conv5,x_bottom_bot_conv5],1)\n",
    "        \n",
    "        \n",
    "        flatten = x_cat.view(x_cat.size(0), -1)\n",
    "        \n",
    "        output = self.classifier(flatten)\n",
    "        \n",
    "        #output = F.softmax(output)\n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n",
    "# Weights initialisation\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "net = VehicleColorRecognitionModel()\n",
    "net.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils import data\n",
    "\n",
    "# class Dataset(data.Dataset):\n",
    "#     'Characterizes a dataset for PyTorch'\n",
    "#     def __init__(self, list_IDs, labels):\n",
    "#         'Initialization'\n",
    "#         self.labels = labels\n",
    "#         self.list_IDs = list_IDs\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the total number of samples'\n",
    "#         return len(self.list_IDs)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generates one sample of data'\n",
    "#         # Select sample\n",
    "#         ID = self.list_IDs[index]\n",
    "\n",
    "#         # Load data and get label\n",
    "#         X = torch.load('data/' + ID + '.png')\n",
    "#         y = self.labels[ID]\n",
    "\n",
    "#         return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake data\n",
    "\n",
    "# inputs = torch.rand(batch_size,3,img_size,img_size)\n",
    "# labels = torch.from_numpy(np.random.choice(num_classes,batch_size))\n",
    "# data_loader = [(inputs, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "# doesnt work\n",
    "# image_path = \"Path to your dataset\"\n",
    "\n",
    "# def loadImages(path):\n",
    "#     # Put files into lists and return them as one list of size 4\n",
    "#     image_files = sorted([os.path.join(path, 'training', file)\n",
    "#          for file in os.listdir(path + \"/training\") if      file.endswith('.png')])\n",
    " \n",
    "#     return image_files\n",
    "\n",
    "# # Preprocessing\n",
    "# def processing(data):\n",
    "#     # loading image\n",
    "#     # Getting 3 images to work with \n",
    "#     img = [cv2.imread(i, cv2.IMREAD_COLOR) for i in data]\n",
    "#     print(img)\n",
    "#     print('Original size',img.shape)\n",
    "#     # --------------------------------\n",
    "#     # setting dim of the resize\n",
    "#     height = 220\n",
    "#     width = 220\n",
    "#     dim = (width, height)\n",
    "#     res_img = []\n",
    "#     for i in range(len(img)):\n",
    "#         res = cv2.resize(img[i], dim, interpolation=cv2.INTER_LINEAR)\n",
    "#         res_img.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_img = loadImages(path=\"./data\")\n",
    "# raw_img\n",
    "# print(cv2.imread('/Users/weitat/Projects/fbhackathon/Pytorch_VehicleColorRecognition/data/training/abc.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_tensor(input_tensors, h, w):\n",
    "#     final_output = None\n",
    "#     batch_size, channel, height, width = input_tensors.shape\n",
    "#     #print(input_tensors.shape)\n",
    "#     input_tensors = torch.squeeze(input_tensors, 1)\n",
    "#     #print(input_tensors.shape)\n",
    "#     print(\"hello\")\n",
    "#     for img in input_tensors:\n",
    "#         print(img.shape)\n",
    "#         img_PIL = transforms.ToPILImage()(img)\n",
    "#         img_PIL = torchvision.transforms.Resize([h,w])(img_PIL)\n",
    "#         img_PIL = torchvision.transforms.ToTensor()(img_PIL)\n",
    "#         print(img_PIL.shape)\n",
    "#         if final_output is None:\n",
    "#             final_output = img_PIL\n",
    "#         else:\n",
    "#             final_output = torch.cat((final_output, img_PIL), 0)\n",
    "# #     final_output = torch.unsqueeze(final_output, 1)\n",
    "#     return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.CenterCrop(224),\n",
    "        transforms.ToTensor() \n",
    "     ],\n",
    ")\n",
    "\n",
    "# Load Data from image folder\n",
    "train_path='data/train/'\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=train_path,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load Data from image folder\n",
    "test_path='data/test/'\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=test_path,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "# classes = ('Dancer', 'Undressed_Pink')\n",
    "# partition = {'train': ['00001'], 'validation': ['00002']}\n",
    "# labels = {'00001.png':0, '00002.png':1}\n",
    "\n",
    "\n",
    "# training_set = Dataset(partition['train'], labels)\n",
    "# training_generator = data.DataLoader(training_set, batch_size=batch_size,\n",
    "#                                     shuffle=True, num_workers=1)\n",
    "\n",
    "# validation_set = Dataset(partition['validation'], labels)\n",
    "# validation_generator = data.DataLoader(validation_set, batch_size=batch_size,\n",
    "#                                     shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images_#303765', 'images_#97264f', 'images_#aa4734', 'images_#ac3122']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# it = iter(train_loader)\n",
    "# # it.next()\n",
    "# print(it.dataset)\n",
    "# print(it.next())\n",
    "# img_test = it.next()[0]\n",
    "# print(img_test.shape)\n",
    "# plt.imshow(img_test[0].permute(1,2,0))\n",
    "# test = F.interpolate(img_test, 224)\n",
    "# plt.figure()\n",
    "# plt.imshow(  test[0].permute(1, 2, 0)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "[1,    20] loss: 0.014\n",
      "[1,    40] loss: 0.015\n",
      "[1,    60] loss: 0.015\n",
      "Accuracy of the network on the 10000 test images: 21 %\n",
      "Accuracy of the network on the 10000 train images: 25 %\n",
      "Epoch:  1\n",
      "[2,    20] loss: 0.015\n",
      "[2,    40] loss: 0.015\n",
      "[2,    60] loss: 0.014\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "Accuracy of the network on the 10000 train images: 33 %\n",
      "Epoch:  2\n",
      "[3,    20] loss: 0.013\n",
      "[3,    40] loss: 0.012\n",
      "[3,    60] loss: 0.013\n",
      "Accuracy of the network on the 10000 test images: 37 %\n",
      "Accuracy of the network on the 10000 train images: 44 %\n",
      "Epoch:  3\n",
      "[4,    20] loss: 0.011\n",
      "[4,    40] loss: 0.009\n",
      "[4,    60] loss: 0.010\n",
      "Accuracy of the network on the 10000 test images: 43 %\n",
      "Accuracy of the network on the 10000 train images: 52 %\n",
      "Epoch:  4\n",
      "[5,    20] loss: 0.010\n",
      "[5,    40] loss: 0.009\n",
      "[5,    60] loss: 0.010\n",
      "Accuracy of the network on the 10000 test images: 50 %\n",
      "Accuracy of the network on the 10000 train images: 55 %\n",
      "Epoch:  5\n",
      "[6,    20] loss: 0.011\n",
      "[6,    40] loss: 0.009\n",
      "[6,    60] loss: 0.008\n",
      "Accuracy of the network on the 10000 test images: 44 %\n",
      "Accuracy of the network on the 10000 train images: 47 %\n",
      "Epoch:  6\n",
      "[7,    20] loss: 0.009\n",
      "[7,    40] loss: 0.010\n",
      "[7,    60] loss: 0.010\n",
      "Accuracy of the network on the 10000 test images: 49 %\n",
      "Accuracy of the network on the 10000 train images: 52 %\n",
      "Epoch:  7\n",
      "[8,    20] loss: 0.010\n",
      "[8,    40] loss: 0.009\n",
      "[8,    60] loss: 0.009\n",
      "Accuracy of the network on the 10000 test images: 44 %\n",
      "Accuracy of the network on the 10000 train images: 50 %\n",
      "Epoch:  8\n",
      "[9,    20] loss: 0.008\n",
      "[9,    40] loss: 0.008\n",
      "[9,    60] loss: 0.009\n",
      "Accuracy of the network on the 10000 test images: 50 %\n",
      "Accuracy of the network on the 10000 train images: 56 %\n",
      "Epoch:  9\n",
      "[10,    20] loss: 0.008\n",
      "[10,    40] loss: 0.009\n",
      "[10,    60] loss: 0.007\n",
      "Accuracy of the network on the 10000 test images: 59 %\n",
      "Accuracy of the network on the 10000 train images: 61 %\n",
      "Epoch:  10\n",
      "[11,    20] loss: 0.007\n",
      "[11,    40] loss: 0.006\n",
      "[11,    60] loss: 0.006\n",
      "Accuracy of the network on the 10000 test images: 63 %\n",
      "Accuracy of the network on the 10000 train images: 71 %\n",
      "Epoch:  11\n",
      "[12,    20] loss: 0.006\n",
      "[12,    40] loss: 0.006\n",
      "[12,    60] loss: 0.006\n",
      "Accuracy of the network on the 10000 test images: 74 %\n",
      "Accuracy of the network on the 10000 train images: 77 %\n",
      "Epoch:  12\n",
      "[13,    20] loss: 0.005\n",
      "[13,    40] loss: 0.006\n",
      "[13,    60] loss: 0.006\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "Accuracy of the network on the 10000 train images: 83 %\n",
      "Epoch:  13\n",
      "[14,    20] loss: 0.004\n",
      "[14,    40] loss: 0.006\n",
      "[14,    60] loss: 0.007\n",
      "Accuracy of the network on the 10000 test images: 59 %\n",
      "Accuracy of the network on the 10000 train images: 65 %\n",
      "Epoch:  14\n",
      "[15,    20] loss: 0.008\n",
      "[15,    40] loss: 0.006\n",
      "[15,    60] loss: 0.006\n",
      "Accuracy of the network on the 10000 test images: 62 %\n",
      "Accuracy of the network on the 10000 train images: 71 %\n",
      "Epoch:  15\n",
      "[16,    20] loss: 0.006\n",
      "[16,    40] loss: 0.005\n",
      "[16,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "Accuracy of the network on the 10000 train images: 78 %\n",
      "Epoch:  16\n",
      "[17,    20] loss: 0.007\n",
      "[17,    40] loss: 0.004\n",
      "[17,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "Accuracy of the network on the 10000 train images: 88 %\n",
      "Epoch:  17\n",
      "[18,    20] loss: 0.005\n",
      "[18,    40] loss: 0.003\n",
      "[18,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 75 %\n",
      "Accuracy of the network on the 10000 train images: 82 %\n",
      "Epoch:  18\n",
      "[19,    20] loss: 0.005\n",
      "[19,    40] loss: 0.004\n",
      "[19,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "Accuracy of the network on the 10000 train images: 90 %\n",
      "Epoch:  19\n",
      "[20,    20] loss: 0.001\n",
      "[20,    40] loss: 0.001\n",
      "[20,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 train images: 94 %\n",
      "Epoch:  20\n",
      "[21,    20] loss: 0.006\n",
      "[21,    40] loss: 0.008\n",
      "[21,    60] loss: 0.009\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "Accuracy of the network on the 10000 train images: 77 %\n",
      "Epoch:  21\n",
      "[22,    20] loss: 0.004\n",
      "[22,    40] loss: 0.005\n",
      "[22,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 75 %\n",
      "Accuracy of the network on the 10000 train images: 86 %\n",
      "Epoch:  22\n",
      "[23,    20] loss: 0.003\n",
      "[23,    40] loss: 0.003\n",
      "[23,    60] loss: 0.005\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "Accuracy of the network on the 10000 train images: 84 %\n",
      "Epoch:  23\n",
      "[24,    20] loss: 0.004\n",
      "[24,    40] loss: 0.006\n",
      "[24,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 train images: 94 %\n",
      "Epoch:  24\n",
      "[25,    20] loss: 0.002\n",
      "[25,    40] loss: 0.002\n",
      "[25,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "Accuracy of the network on the 10000 train images: 93 %\n",
      "Epoch:  25\n",
      "[26,    20] loss: 0.002\n",
      "[26,    40] loss: 0.002\n",
      "[26,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 train images: 96 %\n",
      "Epoch:  26\n",
      "[27,    20] loss: 0.001\n",
      "[27,    40] loss: 0.003\n",
      "[27,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  27\n",
      "[28,    20] loss: 0.001\n",
      "[28,    40] loss: 0.001\n",
      "[28,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "Accuracy of the network on the 10000 train images: 95 %\n",
      "Epoch:  28\n",
      "[29,    20] loss: 0.001\n",
      "[29,    40] loss: 0.004\n",
      "[29,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "Accuracy of the network on the 10000 train images: 93 %\n",
      "Epoch:  29\n",
      "[30,    20] loss: 0.001\n",
      "[30,    40] loss: 0.001\n",
      "[30,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy of the network on the 10000 train images: 94 %\n",
      "Epoch:  30\n",
      "[31,    20] loss: 0.001\n",
      "[31,    40] loss: 0.004\n",
      "[31,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 74 %\n",
      "Accuracy of the network on the 10000 train images: 90 %\n",
      "Epoch:  31\n",
      "[32,    20] loss: 0.004\n",
      "[32,    40] loss: 0.002\n",
      "[32,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  32\n",
      "[33,    20] loss: 0.000\n",
      "[33,    40] loss: 0.001\n",
      "[33,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  33\n",
      "[34,    20] loss: 0.002\n",
      "[34,    40] loss: 0.001\n",
      "[34,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  34\n",
      "[35,    20] loss: 0.001\n",
      "[35,    40] loss: 0.001\n",
      "[35,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  35\n",
      "[36,    20] loss: 0.003\n",
      "[36,    40] loss: 0.002\n",
      "[36,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "Accuracy of the network on the 10000 train images: 94 %\n",
      "Epoch:  36\n",
      "[37,    20] loss: 0.002\n",
      "[37,    40] loss: 0.002\n",
      "[37,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "Accuracy of the network on the 10000 train images: 87 %\n",
      "Epoch:  37\n",
      "[38,    20] loss: 0.004\n",
      "[38,    40] loss: 0.001\n",
      "[38,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  38\n",
      "[39,    20] loss: 0.001\n",
      "[39,    40] loss: 0.000\n",
      "[39,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy of the network on the 10000 train images: 96 %\n",
      "Epoch:  39\n",
      "[40,    20] loss: 0.000\n",
      "[40,    40] loss: 0.001\n",
      "[40,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  40\n",
      "[41,    20] loss: 0.002\n",
      "[41,    40] loss: 0.001\n",
      "[41,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 98 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  41\n",
      "[42,    20] loss: 0.001\n",
      "[42,    40] loss: 0.001\n",
      "[42,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 59 %\n",
      "Accuracy of the network on the 10000 train images: 62 %\n",
      "Epoch:  42\n",
      "[43,    20] loss: 0.007\n",
      "[43,    40] loss: 0.005\n",
      "[43,    60] loss: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 75 %\n",
      "Accuracy of the network on the 10000 train images: 87 %\n",
      "Epoch:  43\n",
      "[44,    20] loss: 0.004\n",
      "[44,    40] loss: 0.003\n",
      "[44,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 75 %\n",
      "Accuracy of the network on the 10000 train images: 83 %\n",
      "Epoch:  44\n",
      "[45,    20] loss: 0.002\n",
      "[45,    40] loss: 0.002\n",
      "[45,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  45\n",
      "[46,    20] loss: 0.002\n",
      "[46,    40] loss: 0.001\n",
      "[46,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  46\n",
      "[47,    20] loss: 0.003\n",
      "[47,    40] loss: 0.004\n",
      "[47,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "Accuracy of the network on the 10000 train images: 93 %\n",
      "Epoch:  47\n",
      "[48,    20] loss: 0.001\n",
      "[48,    40] loss: 0.001\n",
      "[48,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  48\n",
      "[49,    20] loss: 0.001\n",
      "[49,    40] loss: 0.001\n",
      "[49,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  49\n",
      "[50,    20] loss: 0.000\n",
      "[50,    40] loss: 0.002\n",
      "[50,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  50\n",
      "[51,    20] loss: 0.002\n",
      "[51,    40] loss: 0.001\n",
      "[51,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  51\n",
      "[52,    20] loss: 0.000\n",
      "[52,    40] loss: 0.000\n",
      "[52,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  52\n",
      "[53,    20] loss: 0.000\n",
      "[53,    40] loss: 0.002\n",
      "[53,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  53\n",
      "[54,    20] loss: 0.000\n",
      "[54,    40] loss: 0.000\n",
      "[54,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  54\n",
      "[55,    20] loss: 0.000\n",
      "[55,    40] loss: 0.000\n",
      "[55,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  55\n",
      "[56,    20] loss: 0.000\n",
      "[56,    40] loss: 0.000\n",
      "[56,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 98 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  56\n",
      "[57,    20] loss: 0.001\n",
      "[57,    40] loss: 0.000\n",
      "[57,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  57\n",
      "[58,    20] loss: 0.002\n",
      "[58,    40] loss: 0.000\n",
      "[58,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  58\n",
      "[59,    20] loss: 0.000\n",
      "[59,    40] loss: 0.000\n",
      "[59,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  59\n",
      "[60,    20] loss: 0.000\n",
      "[60,    40] loss: 0.000\n",
      "[60,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 97 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  60\n",
      "[61,    20] loss: 0.003\n",
      "[61,    40] loss: 0.003\n",
      "[61,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  61\n",
      "[62,    20] loss: 0.001\n",
      "[62,    40] loss: 0.002\n",
      "[62,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  62\n",
      "[63,    20] loss: 0.002\n",
      "[63,    40] loss: 0.005\n",
      "[63,    60] loss: 0.005\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "Accuracy of the network on the 10000 train images: 76 %\n",
      "Epoch:  63\n",
      "[64,    20] loss: 0.004\n",
      "[64,    40] loss: 0.004\n",
      "[64,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "Accuracy of the network on the 10000 train images: 77 %\n",
      "Epoch:  64\n",
      "[65,    20] loss: 0.002\n",
      "[65,    40] loss: 0.004\n",
      "[65,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 60 %\n",
      "Accuracy of the network on the 10000 train images: 79 %\n",
      "Epoch:  65\n",
      "[66,    20] loss: 0.004\n",
      "[66,    40] loss: 0.004\n",
      "[66,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "Accuracy of the network on the 10000 train images: 76 %\n",
      "Epoch:  66\n",
      "[67,    20] loss: 0.003\n",
      "[67,    40] loss: 0.004\n",
      "[67,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "Accuracy of the network on the 10000 train images: 76 %\n",
      "Epoch:  67\n",
      "[68,    20] loss: 0.003\n",
      "[68,    40] loss: 0.004\n",
      "[68,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 60 %\n",
      "Accuracy of the network on the 10000 train images: 78 %\n",
      "Epoch:  68\n",
      "[69,    20] loss: 0.004\n",
      "[69,    40] loss: 0.005\n",
      "[69,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 60 %\n",
      "Accuracy of the network on the 10000 train images: 84 %\n",
      "Epoch:  69\n",
      "[70,    20] loss: 0.004\n",
      "[70,    40] loss: 0.004\n",
      "[70,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 59 %\n",
      "Accuracy of the network on the 10000 train images: 87 %\n",
      "Epoch:  70\n",
      "[71,    20] loss: 0.004\n",
      "[71,    40] loss: 0.004\n",
      "[71,    60] loss: 0.003\n",
      "Accuracy of the network on the 10000 test images: 69 %\n",
      "Accuracy of the network on the 10000 train images: 89 %\n",
      "Epoch:  71\n",
      "[72,    20] loss: 0.003\n",
      "[72,    40] loss: 0.002\n",
      "[72,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 73 %\n",
      "Accuracy of the network on the 10000 train images: 89 %\n",
      "Epoch:  72\n",
      "[73,    20] loss: 0.003\n",
      "[73,    40] loss: 0.002\n",
      "[73,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  73\n",
      "[74,    20] loss: 0.001\n",
      "[74,    40] loss: 0.002\n",
      "[74,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  74\n",
      "[75,    20] loss: 0.002\n",
      "[75,    40] loss: 0.003\n",
      "[75,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 train images: 97 %\n",
      "Epoch:  75\n",
      "[76,    20] loss: 0.001\n",
      "[76,    40] loss: 0.001\n",
      "[76,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  76\n",
      "[77,    20] loss: 0.000\n",
      "[77,    40] loss: 0.000\n",
      "[77,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  77\n",
      "[78,    20] loss: 0.000\n",
      "[78,    40] loss: 0.000\n",
      "[78,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  78\n",
      "[79,    20] loss: 0.001\n",
      "[79,    40] loss: 0.000\n",
      "[79,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  79\n",
      "[80,    20] loss: 0.000\n",
      "[80,    40] loss: 0.001\n",
      "[80,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  80\n",
      "[81,    20] loss: 0.001\n",
      "[81,    40] loss: 0.001\n",
      "[81,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 98 %\n",
      "Epoch:  81\n",
      "[82,    20] loss: 0.000\n",
      "[82,    40] loss: 0.000\n",
      "[82,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  82\n",
      "[83,    20] loss: 0.000\n",
      "[83,    40] loss: 0.000\n",
      "[83,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  83\n",
      "[84,    20] loss: 0.000\n",
      "[84,    40] loss: 0.000\n",
      "[84,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  84\n",
      "[85,    20] loss: 0.000\n",
      "[85,    40] loss: 0.000\n",
      "[85,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 94 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  85\n",
      "[86,    20] loss: 0.000\n",
      "[86,    40] loss: 0.000\n",
      "[86,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "Accuracy of the network on the 10000 train images: 99 %\n",
      "Epoch:  86\n",
      "[87,    20] loss: 0.000\n",
      "[87,    40] loss: 0.000\n",
      "[87,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  87\n",
      "[88,    20] loss: 0.000\n",
      "[88,    40] loss: 0.000\n",
      "[88,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  88\n",
      "[89,    20] loss: 0.000\n",
      "[89,    40] loss: 0.000\n",
      "[89,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  89\n",
      "[90,    20] loss: 0.000\n",
      "[90,    40] loss: 0.000\n",
      "[90,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 94 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  90\n",
      "[91,    20] loss: 0.000\n",
      "[91,    40] loss: 0.000\n",
      "[91,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 93 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  91\n",
      "[92,    20] loss: 0.000\n",
      "[92,    40] loss: 0.001\n",
      "[92,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "Accuracy of the network on the 10000 train images: 94 %\n",
      "Epoch:  92\n",
      "[93,    20] loss: 0.000\n",
      "[93,    40] loss: 0.001\n",
      "[93,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 96 %\n",
      "Accuracy of the network on the 10000 train images: 100 %\n",
      "Epoch:  93\n",
      "[94,    20] loss: 0.000\n",
      "[94,    40] loss: 0.000\n",
      "[94,    60] loss: 0.000\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "Accuracy of the network on the 10000 train images: 92 %\n",
      "Epoch:  94\n",
      "[95,    20] loss: 0.013\n",
      "[95,    40] loss: 0.009\n",
      "[95,    60] loss: 0.004\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "Accuracy of the network on the 10000 train images: 94 %\n",
      "Epoch:  95\n",
      "[96,    20] loss: 0.002\n",
      "[96,    40] loss: 0.001\n",
      "[96,    60] loss: 0.007\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "Accuracy of the network on the 10000 train images: 78 %\n",
      "Epoch:  96\n",
      "[97,    20] loss: 0.005\n",
      "[97,    40] loss: 0.003\n",
      "[97,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "Accuracy of the network on the 10000 train images: 89 %\n",
      "Epoch:  97\n",
      "[98,    20] loss: 0.002\n",
      "[98,    40] loss: 0.003\n",
      "[98,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "Accuracy of the network on the 10000 train images: 92 %\n",
      "Epoch:  98\n",
      "[99,    20] loss: 0.002\n",
      "[99,    40] loss: 0.001\n",
      "[99,    60] loss: 0.001\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "Accuracy of the network on the 10000 train images: 92 %\n",
      "Epoch:  99\n",
      "[100,    20] loss: 0.002\n",
      "[100,    40] loss: 0.002\n",
      "[100,    60] loss: 0.002\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "Accuracy of the network on the 10000 train images: 96 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    print(\"Epoch: \",epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "#         print(inputs.shape)\n",
    "#         inputs=resize_tensor(inputs,224,224)\n",
    "#         print(inputs.shape)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))    \n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 train images: %d %%' % (\n",
    "        100 * correct / total))    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './lipstick_net_test1.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = VehicleColorRecognitionModel()\n",
    "load_model.zload_state_dict(torch.load(\"./trained_parameter/BEST_lipstick_net.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_#97264f\n"
     ]
    }
   ],
   "source": [
    "classes = ['images_#303765', 'images_#97264f', 'images_#aa4734', 'images_#ac3122']\n",
    "\n",
    "# Load Model and 1 forward passs\n",
    "load_model = VehicleColorRecognitionModel()\n",
    "load_model.load_state_dict(torch.load(\"./trained_parameter/BEST_lipstick_net.pth\"))\n",
    "net=load_model \n",
    "# Load Data from image folder\n",
    "input_path = \"../input/\"\n",
    "\n",
    "input_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=train_path,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    input_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    iter_ = iter(loader)\n",
    "    img_tensor = iter_.next()[0]\n",
    "    outputs = load_model(img_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print(classes[predicted])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {}\n",
    "data['lipstick'] = []\n",
    "\n",
    "url = 'https://www.maybelline.com/lip-makeup/lipstick/superstay-matte-ink-city-edition-liquid-lipstick-makeup'\n",
    "if(predicted == 0):\n",
    "    data['lipstick'].append({\n",
    "        'color': '#303765',\n",
    "        'name': 'Explorer',\n",
    "        'url': url\n",
    "    })\n",
    "elif(predicted == 1):\n",
    "    data['lipstick'].append({\n",
    "    'color': '#97264F',\n",
    "    'name': 'Artist',\n",
    "    'url': url\n",
    "    })\n",
    "elif(predicted == 2):\n",
    "    data['lipstick'].append({\n",
    "    'color': '#AA4734',\n",
    "    'name': 'Globetrotter',\n",
    "    'url': url\n",
    "    })\n",
    "elif(predicted == 3):\n",
    "    data['lipstick'].append({\n",
    "    'color': '#AC3122',\n",
    "    'name': 'Dancer',\n",
    "    'url': url\n",
    "    })\n",
    "    \n",
    "with open('../output/output.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
